{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 00:04:56.067961: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from train_model_norm import train\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from yellowbrick.regressor import ResidualsPlot, PredictionError\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (8, 4)\n",
    "rcParams['figure.dpi'] = 100\n",
    "rcParams['font.size'] = 8\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['axes.facecolor'] = '#ffffff'\n",
    "rcParams['lines.linewidth'] = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hyperparameter={\n",
    "\"num_nearest\":60,\n",
    "\"sigma\":2,\n",
    "\"learning_rate\":0.001,\n",
    "\"batch_size\":250,\n",
    "\"num_neuron\":60,\n",
    "\"num_layers\":3,\n",
    "\"size_embedded\":50,\n",
    "\"num_nearest_geo\":45,\n",
    "\"num_nearest_eucli\":45,\n",
    "\"id_dataset\":'kc',\n",
    "\"epochs\":300,\n",
    "\"optimier\":'adam',\n",
    "\"validation_split\":0.1,\n",
    "\"label\":'asi_kc',\n",
    "\"early_stopping\": False,\n",
    "\"graph_label\":'matrix',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial = train(**hyperparameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/smhan/.conda/envs/TF2/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 00:04:57.591599: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-22 00:04:57.595564: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-22 00:04:57.595822: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-22 00:04:57.596544: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-22 00:04:57.598944: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-22 00:04:57.599200: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-22 00:04:57.599433: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-22 00:04:57.969480: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-22 00:04:57.969749: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-22 00:04:57.969986: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-22 00:04:57.970181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22273 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 00:05:00.002010: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-08-22 00:05:00.004651: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x55c10ed0e660 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-22 00:05:00.004670: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-08-22 00:05:00.009626: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-22 00:05:00.096165: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/63 [=========================>....] - ETA: 0s - loss: 5.1501 - root_mean_squared_error: 6.8640 \n",
      "Epoch 1: val_loss improved from inf to 0.83462, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 3s 7ms/step - loss: 4.6641 - root_mean_squared_error: 6.4712 - val_loss: 0.8346 - val_root_mean_squared_error: 1.1336 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.5649 - root_mean_squared_error: 0.8204\n",
      "Epoch 2: val_loss improved from 0.83462 to 0.31660, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5426 - root_mean_squared_error: 0.7931 - val_loss: 0.3166 - val_root_mean_squared_error: 0.4378 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.2158 - root_mean_squared_error: 0.3117\n",
      "Epoch 3: val_loss improved from 0.31660 to 0.12223, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.2069 - root_mean_squared_error: 0.3022 - val_loss: 0.1222 - val_root_mean_squared_error: 0.1678 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1105 - root_mean_squared_error: 0.1576\n",
      "Epoch 4: val_loss improved from 0.12223 to 0.09513, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1093 - root_mean_squared_error: 0.1556 - val_loss: 0.0951 - val_root_mean_squared_error: 0.1340 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0809 - root_mean_squared_error: 0.1150\n",
      "Epoch 5: val_loss improved from 0.09513 to 0.07426, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0797 - root_mean_squared_error: 0.1140 - val_loss: 0.0743 - val_root_mean_squared_error: 0.1043 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0823 - root_mean_squared_error: 0.1093\n",
      "Epoch 6: val_loss improved from 0.07426 to 0.06759, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0810 - root_mean_squared_error: 0.1080 - val_loss: 0.0676 - val_root_mean_squared_error: 0.0935 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0577 - root_mean_squared_error: 0.0820\n",
      "Epoch 7: val_loss improved from 0.06759 to 0.06473, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0573 - root_mean_squared_error: 0.0813 - val_loss: 0.0647 - val_root_mean_squared_error: 0.0862 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0570 - root_mean_squared_error: 0.0793\n",
      "Epoch 8: val_loss did not improve from 0.06473\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0569 - root_mean_squared_error: 0.0791 - val_loss: 0.0666 - val_root_mean_squared_error: 0.0883 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0543 - root_mean_squared_error: 0.0738\n",
      "Epoch 9: val_loss improved from 0.06473 to 0.04112, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0532 - root_mean_squared_error: 0.0728 - val_loss: 0.0411 - val_root_mean_squared_error: 0.0608 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0468 - root_mean_squared_error: 0.0649\n",
      "Epoch 10: val_loss did not improve from 0.04112\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0466 - root_mean_squared_error: 0.0645 - val_loss: 0.0713 - val_root_mean_squared_error: 0.0874 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0471 - root_mean_squared_error: 0.0642\n",
      "Epoch 11: val_loss improved from 0.04112 to 0.04065, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0483 - root_mean_squared_error: 0.0651 - val_loss: 0.0406 - val_root_mean_squared_error: 0.0574 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0480 - root_mean_squared_error: 0.0632\n",
      "Epoch 12: val_loss did not improve from 0.04065\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0477 - root_mean_squared_error: 0.0627 - val_loss: 0.0501 - val_root_mean_squared_error: 0.0645 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0353 - root_mean_squared_error: 0.0492\n",
      "Epoch 13: val_loss did not improve from 0.04065\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0349 - root_mean_squared_error: 0.0487 - val_loss: 0.0587 - val_root_mean_squared_error: 0.0669 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0412 - root_mean_squared_error: 0.0545\n",
      "Epoch 14: val_loss improved from 0.04065 to 0.02670, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0403 - root_mean_squared_error: 0.0537 - val_loss: 0.0267 - val_root_mean_squared_error: 0.0391 - lr: 0.0010\n",
      "Epoch 15/300\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0401 - root_mean_squared_error: 0.0539\n",
      "Epoch 15: val_loss did not improve from 0.02670\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0411 - root_mean_squared_error: 0.0549 - val_loss: 0.0543 - val_root_mean_squared_error: 0.0645 - lr: 0.0010\n",
      "Epoch 16/300\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0399 - root_mean_squared_error: 0.0519\n",
      "Epoch 16: val_loss did not improve from 0.02670\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0399 - root_mean_squared_error: 0.0517 - val_loss: 0.0390 - val_root_mean_squared_error: 0.0500 - lr: 0.0010\n",
      "Epoch 17/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0384 - root_mean_squared_error: 0.0502\n",
      "Epoch 17: val_loss did not improve from 0.02670\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0389 - root_mean_squared_error: 0.0506 - val_loss: 0.0331 - val_root_mean_squared_error: 0.0454 - lr: 0.0010\n",
      "Epoch 18/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0335 - root_mean_squared_error: 0.0442\n",
      "Epoch 18: val_loss did not improve from 0.02670\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0344 - root_mean_squared_error: 0.0453 - val_loss: 0.0358 - val_root_mean_squared_error: 0.0465 - lr: 0.0010\n",
      "Epoch 19/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0446 - root_mean_squared_error: 0.0594\n",
      "Epoch 19: val_loss improved from 0.02670 to 0.02469, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0430 - root_mean_squared_error: 0.0578 - val_loss: 0.0247 - val_root_mean_squared_error: 0.0341 - lr: 0.0010\n",
      "Epoch 20/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0385 - root_mean_squared_error: 0.0508\n",
      "Epoch 20: val_loss did not improve from 0.02469\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0390 - root_mean_squared_error: 0.0511 - val_loss: 0.0494 - val_root_mean_squared_error: 0.0589 - lr: 0.0010\n",
      "Epoch 21/300\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0335 - root_mean_squared_error: 0.0431\n",
      "Epoch 21: val_loss did not improve from 0.02469\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0332 - root_mean_squared_error: 0.0428 - val_loss: 0.0370 - val_root_mean_squared_error: 0.0463 - lr: 0.0010\n",
      "Epoch 22/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0314 - root_mean_squared_error: 0.0406\n",
      "Epoch 22: val_loss did not improve from 0.02469\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0309 - root_mean_squared_error: 0.0402 - val_loss: 0.0357 - val_root_mean_squared_error: 0.0469 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0448 - root_mean_squared_error: 0.0566\n",
      "Epoch 23: val_loss did not improve from 0.02469\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0483 - root_mean_squared_error: 0.0615 - val_loss: 0.1675 - val_root_mean_squared_error: 0.1705 - lr: 0.0010\n",
      "Epoch 24/300\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0876 - root_mean_squared_error: 0.0986\n",
      "Epoch 24: val_loss did not improve from 0.02469\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0829 - root_mean_squared_error: 0.0947 - val_loss: 0.0434 - val_root_mean_squared_error: 0.0544 - lr: 0.0010\n",
      "Epoch 25/300\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0218 - root_mean_squared_error: 0.0307\n",
      "Epoch 25: val_loss improved from 0.02469 to 0.01805, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0215 - root_mean_squared_error: 0.0303 - val_loss: 0.0180 - val_root_mean_squared_error: 0.0262 - lr: 1.0000e-04\n",
      "Epoch 26/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0164 - root_mean_squared_error: 0.0243\n",
      "Epoch 26: val_loss improved from 0.01805 to 0.01706, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0165 - root_mean_squared_error: 0.0243 - val_loss: 0.0171 - val_root_mean_squared_error: 0.0250 - lr: 1.0000e-04\n",
      "Epoch 27/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0158 - root_mean_squared_error: 0.0236\n",
      "Epoch 27: val_loss improved from 0.01706 to 0.01662, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0157 - root_mean_squared_error: 0.0234 - val_loss: 0.0166 - val_root_mean_squared_error: 0.0248 - lr: 1.0000e-04\n",
      "Epoch 28/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0153 - root_mean_squared_error: 0.0229\n",
      "Epoch 28: val_loss improved from 0.01662 to 0.01643, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0154 - root_mean_squared_error: 0.0230 - val_loss: 0.0164 - val_root_mean_squared_error: 0.0248 - lr: 1.0000e-04\n",
      "Epoch 29/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0151 - root_mean_squared_error: 0.0224\n",
      "Epoch 29: val_loss improved from 0.01643 to 0.01624, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0151 - root_mean_squared_error: 0.0227 - val_loss: 0.0162 - val_root_mean_squared_error: 0.0241 - lr: 1.0000e-04\n",
      "Epoch 30/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0151 - root_mean_squared_error: 0.0225\n",
      "Epoch 30: val_loss improved from 0.01624 to 0.01616, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0151 - root_mean_squared_error: 0.0225 - val_loss: 0.0162 - val_root_mean_squared_error: 0.0243 - lr: 1.0000e-04\n",
      "Epoch 31/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0149 - root_mean_squared_error: 0.0221\n",
      "Epoch 31: val_loss did not improve from 0.01616\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0150 - root_mean_squared_error: 0.0223 - val_loss: 0.0162 - val_root_mean_squared_error: 0.0241 - lr: 1.0000e-04\n",
      "Epoch 32/300\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0147 - root_mean_squared_error: 0.0218\n",
      "Epoch 32: val_loss did not improve from 0.01616\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0147 - root_mean_squared_error: 0.0220 - val_loss: 0.0164 - val_root_mean_squared_error: 0.0243 - lr: 1.0000e-04\n",
      "Epoch 33/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0144 - root_mean_squared_error: 0.0217\n",
      "Epoch 33: val_loss improved from 0.01616 to 0.01577, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0145 - root_mean_squared_error: 0.0217 - val_loss: 0.0158 - val_root_mean_squared_error: 0.0232 - lr: 1.0000e-04\n",
      "Epoch 34/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0146 - root_mean_squared_error: 0.0217\n",
      "Epoch 34: val_loss improved from 0.01577 to 0.01546, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0146 - root_mean_squared_error: 0.0217 - val_loss: 0.0155 - val_root_mean_squared_error: 0.0231 - lr: 1.0000e-04\n",
      "Epoch 35/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0143 - root_mean_squared_error: 0.0214\n",
      "Epoch 35: val_loss improved from 0.01546 to 0.01527, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0143 - root_mean_squared_error: 0.0214 - val_loss: 0.0153 - val_root_mean_squared_error: 0.0227 - lr: 1.0000e-04\n",
      "Epoch 36/300\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0139 - root_mean_squared_error: 0.0207\n",
      "Epoch 36: val_loss did not improve from 0.01527\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0140 - root_mean_squared_error: 0.0210 - val_loss: 0.0157 - val_root_mean_squared_error: 0.0228 - lr: 1.0000e-04\n",
      "Epoch 37/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0139 - root_mean_squared_error: 0.0209\n",
      "Epoch 37: val_loss improved from 0.01527 to 0.01503, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0139 - root_mean_squared_error: 0.0208 - val_loss: 0.0150 - val_root_mean_squared_error: 0.0225 - lr: 1.0000e-04\n",
      "Epoch 38/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0138 - root_mean_squared_error: 0.0207\n",
      "Epoch 38: val_loss improved from 0.01503 to 0.01481, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0137 - root_mean_squared_error: 0.0206 - val_loss: 0.0148 - val_root_mean_squared_error: 0.0221 - lr: 1.0000e-04\n",
      "Epoch 39/300\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0136 - root_mean_squared_error: 0.0203\n",
      "Epoch 39: val_loss did not improve from 0.01481\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0136 - root_mean_squared_error: 0.0203 - val_loss: 0.0148 - val_root_mean_squared_error: 0.0225 - lr: 1.0000e-04\n",
      "Epoch 40/300\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0134 - root_mean_squared_error: 0.0198\n",
      "Epoch 40: val_loss did not improve from 0.01481\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0135 - root_mean_squared_error: 0.0202 - val_loss: 0.0148 - val_root_mean_squared_error: 0.0219 - lr: 1.0000e-04\n",
      "Epoch 41/300\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0132 - root_mean_squared_error: 0.0199\n",
      "Epoch 41: val_loss did not improve from 0.01481\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0133 - root_mean_squared_error: 0.0200 - val_loss: 0.0151 - val_root_mean_squared_error: 0.0225 - lr: 1.0000e-04\n",
      "Epoch 42/300\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0132 - root_mean_squared_error: 0.0198\n",
      "Epoch 42: val_loss improved from 0.01481 to 0.01423, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0132 - root_mean_squared_error: 0.0198 - val_loss: 0.0142 - val_root_mean_squared_error: 0.0216 - lr: 1.0000e-04\n",
      "Epoch 43/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0133 - root_mean_squared_error: 0.0196\n",
      "Epoch 43: val_loss improved from 0.01423 to 0.01414, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0133 - root_mean_squared_error: 0.0198 - val_loss: 0.0141 - val_root_mean_squared_error: 0.0215 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0131 - root_mean_squared_error: 0.0195\n",
      "Epoch 44: val_loss did not improve from 0.01414\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0131 - root_mean_squared_error: 0.0196 - val_loss: 0.0147 - val_root_mean_squared_error: 0.0213 - lr: 1.0000e-04\n",
      "Epoch 45/300\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0128 - root_mean_squared_error: 0.0189\n",
      "Epoch 45: val_loss improved from 0.01414 to 0.01391, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0128 - root_mean_squared_error: 0.0192 - val_loss: 0.0139 - val_root_mean_squared_error: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 46/300\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0127 - root_mean_squared_error: 0.0189\n",
      "Epoch 46: val_loss improved from 0.01391 to 0.01381, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0127 - root_mean_squared_error: 0.0190 - val_loss: 0.0138 - val_root_mean_squared_error: 0.0211 - lr: 1.0000e-04\n",
      "Epoch 47/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0124 - root_mean_squared_error: 0.0187\n",
      "Epoch 47: val_loss improved from 0.01381 to 0.01371, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0125 - root_mean_squared_error: 0.0187 - val_loss: 0.0137 - val_root_mean_squared_error: 0.0208 - lr: 1.0000e-04\n",
      "Epoch 48/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0124 - root_mean_squared_error: 0.0185\n",
      "Epoch 48: val_loss improved from 0.01371 to 0.01345, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0125 - root_mean_squared_error: 0.0186 - val_loss: 0.0135 - val_root_mean_squared_error: 0.0205 - lr: 1.0000e-04\n",
      "Epoch 49/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0123 - root_mean_squared_error: 0.0182\n",
      "Epoch 49: val_loss did not improve from 0.01345\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0123 - root_mean_squared_error: 0.0183 - val_loss: 0.0135 - val_root_mean_squared_error: 0.0204 - lr: 1.0000e-04\n",
      "Epoch 50/300\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0121 - root_mean_squared_error: 0.0182\n",
      "Epoch 50: val_loss improved from 0.01345 to 0.01327, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0121 - root_mean_squared_error: 0.0182 - val_loss: 0.0133 - val_root_mean_squared_error: 0.0199 - lr: 1.0000e-04\n",
      "Epoch 51/300\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0122 - root_mean_squared_error: 0.0180\n",
      "Epoch 51: val_loss did not improve from 0.01327\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0121 - root_mean_squared_error: 0.0180 - val_loss: 0.0133 - val_root_mean_squared_error: 0.0200 - lr: 1.0000e-04\n",
      "Epoch 52/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0120 - root_mean_squared_error: 0.0179\n",
      "Epoch 52: val_loss did not improve from 0.01327\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0120 - root_mean_squared_error: 0.0179 - val_loss: 0.0135 - val_root_mean_squared_error: 0.0199 - lr: 1.0000e-04\n",
      "Epoch 53/300\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0120 - root_mean_squared_error: 0.0178\n",
      "Epoch 53: val_loss improved from 0.01327 to 0.01297, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0119 - root_mean_squared_error: 0.0177 - val_loss: 0.0130 - val_root_mean_squared_error: 0.0198 - lr: 1.0000e-04\n",
      "Epoch 54/300\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0116 - root_mean_squared_error: 0.0175\n",
      "Epoch 54: val_loss did not improve from 0.01297\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0116 - root_mean_squared_error: 0.0174 - val_loss: 0.0138 - val_root_mean_squared_error: 0.0198 - lr: 1.0000e-04\n",
      "Epoch 55/300\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0119 - root_mean_squared_error: 0.0176\n",
      "Epoch 55: val_loss did not improve from 0.01297\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0118 - root_mean_squared_error: 0.0175 - val_loss: 0.0133 - val_root_mean_squared_error: 0.0195 - lr: 1.0000e-04\n",
      "Epoch 56/300\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0118 - root_mean_squared_error: 0.0174\n",
      "Epoch 56: val_loss improved from 0.01297 to 0.01293, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0119 - root_mean_squared_error: 0.0175 - val_loss: 0.0129 - val_root_mean_squared_error: 0.0198 - lr: 1.0000e-04\n",
      "Epoch 57/300\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0117 - root_mean_squared_error: 0.0173\n",
      "Epoch 57: val_loss improved from 0.01293 to 0.01260, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0116 - root_mean_squared_error: 0.0172 - val_loss: 0.0126 - val_root_mean_squared_error: 0.0187 - lr: 1.0000e-04\n",
      "Epoch 58/300\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0116 - root_mean_squared_error: 0.0171\n",
      "Epoch 58: val_loss improved from 0.01260 to 0.01242, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0115 - root_mean_squared_error: 0.0170 - val_loss: 0.0124 - val_root_mean_squared_error: 0.0186 - lr: 1.0000e-04\n",
      "Epoch 59/300\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0111 - root_mean_squared_error: 0.0166\n",
      "Epoch 59: val_loss improved from 0.01242 to 0.01223, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0111 - root_mean_squared_error: 0.0166 - val_loss: 0.0122 - val_root_mean_squared_error: 0.0186 - lr: 1.0000e-04\n",
      "Epoch 60/300\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0115 - root_mean_squared_error: 0.0168\n",
      "Epoch 60: val_loss improved from 0.01223 to 0.01193, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0113 - root_mean_squared_error: 0.0167 - val_loss: 0.0119 - val_root_mean_squared_error: 0.0182 - lr: 1.0000e-04\n",
      "Epoch 61/300\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0110 - root_mean_squared_error: 0.0164\n",
      "Epoch 61: val_loss did not improve from 0.01193\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0110 - root_mean_squared_error: 0.0163 - val_loss: 0.0133 - val_root_mean_squared_error: 0.0191 - lr: 1.0000e-04\n",
      "Epoch 62/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0108 - root_mean_squared_error: 0.0161\n",
      "Epoch 62: val_loss did not improve from 0.01193\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0109 - root_mean_squared_error: 0.0162 - val_loss: 0.0124 - val_root_mean_squared_error: 0.0186 - lr: 1.0000e-04\n",
      "Epoch 63/300\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0110 - root_mean_squared_error: 0.0162\n",
      "Epoch 63: val_loss did not improve from 0.01193\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0110 - root_mean_squared_error: 0.0162 - val_loss: 0.0120 - val_root_mean_squared_error: 0.0183 - lr: 1.0000e-04\n",
      "Epoch 64/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0108 - root_mean_squared_error: 0.0159\n",
      "Epoch 64: val_loss did not improve from 0.01193\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0108 - root_mean_squared_error: 0.0159 - val_loss: 0.0127 - val_root_mean_squared_error: 0.0187 - lr: 1.0000e-04\n",
      "Epoch 65/300\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0106 - root_mean_squared_error: 0.0157\n",
      "Epoch 65: val_loss improved from 0.01193 to 0.01166, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0107 - root_mean_squared_error: 0.0157 - val_loss: 0.0117 - val_root_mean_squared_error: 0.0178 - lr: 1.0000e-04\n",
      "Epoch 66/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0105 - root_mean_squared_error: 0.0156\n",
      "Epoch 66: val_loss did not improve from 0.01166\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0104 - root_mean_squared_error: 0.0156 - val_loss: 0.0120 - val_root_mean_squared_error: 0.0179 - lr: 1.0000e-04\n",
      "Epoch 67/300\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0105 - root_mean_squared_error: 0.0154\n",
      "Epoch 67: val_loss improved from 0.01166 to 0.01118, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0105 - root_mean_squared_error: 0.0154 - val_loss: 0.0112 - val_root_mean_squared_error: 0.0171 - lr: 1.0000e-04\n",
      "Epoch 68/300\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0105 - root_mean_squared_error: 0.0155\n",
      "Epoch 68: val_loss did not improve from 0.01118\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0104 - root_mean_squared_error: 0.0154 - val_loss: 0.0130 - val_root_mean_squared_error: 0.0183 - lr: 1.0000e-04\n",
      "Epoch 69/300\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0101 - root_mean_squared_error: 0.0151\n",
      "Epoch 69: val_loss did not improve from 0.01118\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0102 - root_mean_squared_error: 0.0151 - val_loss: 0.0120 - val_root_mean_squared_error: 0.0176 - lr: 1.0000e-04\n",
      "Epoch 70/300\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0102 - root_mean_squared_error: 0.0150\n",
      "Epoch 70: val_loss did not improve from 0.01118\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0102 - root_mean_squared_error: 0.0151 - val_loss: 0.0120 - val_root_mean_squared_error: 0.0173 - lr: 1.0000e-04\n",
      "Epoch 71/300\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0100 - root_mean_squared_error: 0.0148\n",
      "Epoch 71: val_loss improved from 0.01118 to 0.01082, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0100 - root_mean_squared_error: 0.0148 - val_loss: 0.0108 - val_root_mean_squared_error: 0.0167 - lr: 1.0000e-04\n",
      "Epoch 72/300\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0110 - root_mean_squared_error: 0.0155\n",
      "Epoch 72: val_loss did not improve from 0.01082\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0109 - root_mean_squared_error: 0.0155 - val_loss: 0.0112 - val_root_mean_squared_error: 0.0170 - lr: 1.0000e-04\n",
      "Epoch 73/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0102 - root_mean_squared_error: 0.0148\n",
      "Epoch 73: val_loss did not improve from 0.01082\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0102 - root_mean_squared_error: 0.0149 - val_loss: 0.0109 - val_root_mean_squared_error: 0.0169 - lr: 1.0000e-04\n",
      "Epoch 74/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0099 - root_mean_squared_error: 0.0145\n",
      "Epoch 74: val_loss did not improve from 0.01082\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0098 - root_mean_squared_error: 0.0145 - val_loss: 0.0115 - val_root_mean_squared_error: 0.0171 - lr: 1.0000e-04\n",
      "Epoch 75/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0098 - root_mean_squared_error: 0.0145\n",
      "Epoch 75: val_loss did not improve from 0.01082\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0098 - root_mean_squared_error: 0.0144 - val_loss: 0.0111 - val_root_mean_squared_error: 0.0171 - lr: 1.0000e-04\n",
      "Epoch 76/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0098 - root_mean_squared_error: 0.0144\n",
      "Epoch 76: val_loss improved from 0.01082 to 0.01061, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0098 - root_mean_squared_error: 0.0144 - val_loss: 0.0106 - val_root_mean_squared_error: 0.0164 - lr: 1.0000e-04\n",
      "Epoch 77/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0097 - root_mean_squared_error: 0.0142\n",
      "Epoch 77: val_loss did not improve from 0.01061\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0097 - root_mean_squared_error: 0.0142 - val_loss: 0.0107 - val_root_mean_squared_error: 0.0162 - lr: 1.0000e-04\n",
      "Epoch 78/300\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0096 - root_mean_squared_error: 0.0141\n",
      "Epoch 78: val_loss improved from 0.01061 to 0.01058, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0095 - root_mean_squared_error: 0.0140 - val_loss: 0.0106 - val_root_mean_squared_error: 0.0160 - lr: 1.0000e-04\n",
      "Epoch 79/300\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0097 - root_mean_squared_error: 0.0141\n",
      "Epoch 79: val_loss did not improve from 0.01058\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0099 - root_mean_squared_error: 0.0143 - val_loss: 0.0106 - val_root_mean_squared_error: 0.0164 - lr: 1.0000e-04\n",
      "Epoch 80/300\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.0096 - root_mean_squared_error: 0.0140\n",
      "Epoch 80: val_loss improved from 0.01058 to 0.01028, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0096 - root_mean_squared_error: 0.0140 - val_loss: 0.0103 - val_root_mean_squared_error: 0.0158 - lr: 1.0000e-04\n",
      "Epoch 81/300\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0094 - root_mean_squared_error: 0.0137\n",
      "Epoch 81: val_loss improved from 0.01028 to 0.01024, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0093 - root_mean_squared_error: 0.0137 - val_loss: 0.0102 - val_root_mean_squared_error: 0.0158 - lr: 1.0000e-04\n",
      "Epoch 82/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0101 - root_mean_squared_error: 0.0142\n",
      "Epoch 82: val_loss did not improve from 0.01024\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0100 - root_mean_squared_error: 0.0142 - val_loss: 0.0110 - val_root_mean_squared_error: 0.0162 - lr: 1.0000e-04\n",
      "Epoch 83/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0093 - root_mean_squared_error: 0.0137\n",
      "Epoch 83: val_loss did not improve from 0.01024\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0093 - root_mean_squared_error: 0.0136 - val_loss: 0.0103 - val_root_mean_squared_error: 0.0159 - lr: 1.0000e-04\n",
      "Epoch 84/300\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0091 - root_mean_squared_error: 0.0134\n",
      "Epoch 84: val_loss did not improve from 0.01024\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0093 - root_mean_squared_error: 0.0135 - val_loss: 0.0115 - val_root_mean_squared_error: 0.0168 - lr: 1.0000e-04\n",
      "Epoch 85/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0091 - root_mean_squared_error: 0.0134\n",
      "Epoch 85: val_loss did not improve from 0.01024\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0091 - root_mean_squared_error: 0.0134 - val_loss: 0.0107 - val_root_mean_squared_error: 0.0163 - lr: 1.0000e-04\n",
      "Epoch 86/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0085 - root_mean_squared_error: 0.0128\n",
      "Epoch 86: val_loss improved from 0.01024 to 0.00963, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0085 - root_mean_squared_error: 0.0128 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0151 - lr: 1.0000e-05\n",
      "Epoch 87/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0084 - root_mean_squared_error: 0.0126\n",
      "Epoch 87: val_loss improved from 0.00963 to 0.00963, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0083 - root_mean_squared_error: 0.0126 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0151 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0083 - root_mean_squared_error: 0.0126\n",
      "Epoch 88: val_loss improved from 0.00963 to 0.00954, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0083 - root_mean_squared_error: 0.0126 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0151 - lr: 1.0000e-05\n",
      "Epoch 89/300\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0083 - root_mean_squared_error: 0.0126\n",
      "Epoch 89: val_loss did not improve from 0.00954\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0083 - root_mean_squared_error: 0.0126 - val_loss: 0.0098 - val_root_mean_squared_error: 0.0153 - lr: 1.0000e-05\n",
      "Epoch 90/300\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0083 - root_mean_squared_error: 0.0126\n",
      "Epoch 90: val_loss did not improve from 0.00954\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0083 - root_mean_squared_error: 0.0126 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0152 - lr: 1.0000e-05\n",
      "Epoch 91/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0083 - root_mean_squared_error: 0.0126\n",
      "Epoch 91: val_loss did not improve from 0.00954\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0083 - root_mean_squared_error: 0.0126 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0153 - lr: 1.0000e-05\n",
      "Epoch 92/300\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0082 - root_mean_squared_error: 0.0125\n",
      "Epoch 92: val_loss did not improve from 0.00954\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0125 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0151 - lr: 1.0000e-06\n",
      "Epoch 93/300\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0082 - root_mean_squared_error: 0.0125\n",
      "Epoch 93: val_loss did not improve from 0.00954\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0125 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0151 - lr: 1.0000e-06\n",
      "Epoch 94/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0082 - root_mean_squared_error: 0.0125\n",
      "Epoch 94: val_loss did not improve from 0.00954\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0125 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0151 - lr: 1.0000e-06\n",
      "Epoch 95/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0082 - root_mean_squared_error: 0.0125\n",
      "Epoch 95: val_loss improved from 0.00954 to 0.00954, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0125 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0151 - lr: 1.0000e-06\n",
      "Epoch 96/300\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0082 - root_mean_squared_error: 0.0124\n",
      "Epoch 96: val_loss did not improve from 0.00954\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0125 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0151 - lr: 1.0000e-06\n",
      "Epoch 97/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0082 - root_mean_squared_error: 0.0124\n",
      "Epoch 97: val_loss improved from 0.00954 to 0.00954, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0082 - root_mean_squared_error: 0.0125 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0151 - lr: 1.0000e-07\n",
      "Epoch 98/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0082 - root_mean_squared_error: 0.0124\n",
      "Epoch 98: val_loss improved from 0.00954 to 0.00954, saving model to /disk1/jupyter/smhan/ASI-revised/output/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0082 - root_mean_squared_error: 0.0125 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0151 - lr: 1.0000e-07\n",
      "Epoch 99/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0082 - root_mean_squared_error: 0.0124\n",
      "Epoch 99: val_loss did not improve from 0.00954\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0125 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0151 - lr: 1.0000e-07\n",
      "Epoch 100/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0082 - root_mean_squared_error: 0.0125\n",
      "Epoch 100: val_loss did not improve from 0.00954\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0125 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0151 - lr: 1.0000e-07\n",
      "Epoch 101/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0082 - root_mean_squared_error: 0.0126\n",
      "Epoch 101: val_loss did not improve from 0.00954\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0125 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0151 - lr: 1.0000e-07\n",
      "Epoch 102/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0082 - root_mean_squared_error: 0.0124\n",
      "Epoch 102: val_loss did not improve from 0.00954\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0125 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0151 - lr: 1.0000e-08\n",
      "Epoch 103/300\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0082 - root_mean_squared_error: 0.0124\n",
      "Epoch 103: val_loss did not improve from 0.00954\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0082 - root_mean_squared_error: 0.0125 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0151 - lr: 1.0000e-08\n",
      "Epoch 104/300\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0083 - root_mean_squared_error: 0.0126\n",
      "Epoch 104: val_loss did not improve from 0.00954\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0082 - root_mean_squared_error: 0.0125 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0151 - lr: 1.0000e-08\n",
      "Epoch 105/300\n",
      "56/63 [=========================>....] - ETA: 0s - loss: 0.0082 - root_mean_squared_error: 0.0125\n",
      "Epoch 105: val_loss did not improve from 0.00954\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0125 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0151 - lr: 1.0000e-08\n",
      "Epoch 106/300\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.0082 - root_mean_squared_error: 0.0124\n",
      "Epoch 106: val_loss did not improve from 0.00954\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0082 - root_mean_squared_error: 0.0125 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0151 - lr: 1.0000e-08\n",
      "Epoch 107/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0082 - root_mean_squared_error: 0.0125\n",
      "Epoch 107: val_loss did not improve from 0.00954\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0082 - root_mean_squared_error: 0.0125 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0151 - lr: 1.0000e-09\n",
      "Epoch 108/300\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.0082 - root_mean_squared_error: 0.0124\n",
      "Epoch 108: val_loss did not improve from 0.00954\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0082 - root_mean_squared_error: 0.0125 - val_loss: 0.0096 - val_root_mean_squared_error: 0.0151 - lr: 1.0000e-09\n",
      "136/136 [==============================] - 0s 1ms/step\n",
      "541/541 [==============================] - 1s 1ms/step\n",
      "70/70 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "70/70 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "dataset,\\\n",
    "result,\\\n",
    "fit,\\\n",
    "embedded_train,\\\n",
    "embedded_test,\\\n",
    "predict_regression_train,\\\n",
    "predict_regression_test = spatial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################# Test ##########################\n",
      "MALE test:.... 0.013095670682676365\n",
      "RMSE test:.... 30756.918923293928\n",
      "MAPE test:.... 1.0444246723789652\n",
      "################# Train ##########################\n",
      "MALE train:.... 0.008335655338366988\n",
      "RMSE train:.... 14272.681012335319\n",
      "MAPE train:.... 0.5601964355223967\n"
     ]
    }
   ],
   "source": [
    "print('################# Test ##########################')\n",
    "print('MALE test:.... {}'.format(result[0]))\n",
    "print('RMSE test:.... {}'.format(result[1]))\n",
    "print('MAPE test:.... {}'.format(result[2]))\n",
    "print('################# Train ##########################')\n",
    "print('MALE train:.... {}'.format(result[3]))\n",
    "print('RMSE train:.... {}'.format(result[4]))\n",
    "print('MAPE train:.... {}'.format(result[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "# metric\n",
    "def metric(pred, label):\n",
    "    assert label.shape == pred.shape\n",
    "    \n",
    "    with np.errstate(divide = 'ignore', invalid = 'ignore'):\n",
    "        mask = np.not_equal(label, 0)\n",
    "        mask = mask.astype(np.float32)\n",
    "        mask /= np.mean(mask)\n",
    "        male = np.abs(np.subtract(np.log(pred), np.log(label))).astype(np.float32)\n",
    "        male = np.nan_to_num(male * mask)\n",
    "        male = np.mean(male)\n",
    "        mae = np.abs(np.subtract(pred, label)).astype(np.float32)\n",
    "        rmse = np.square(mae)\n",
    "        mape = np.divide(mae, label)\n",
    "        mae = np.nan_to_num(mae * mask)\n",
    "        mae = np.mean(mae)\n",
    "        rmse = np.nan_to_num(rmse * mask)\n",
    "        rmse = np.sqrt(np.mean(rmse))\n",
    "        mape = np.nan_to_num(mape * mask)\n",
    "        mape = np.median(mape) # np.mean(mape) -- author leverages median\n",
    "    return male, rmse, mape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01309567, 30756.92, 0.01044424672379033)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label = np.exp(dataset.y_test)\n",
    "y_pred = np.exp(result[6].flatten())\n",
    "metric(y_pred, y_label) # should be same value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f388c0f0340>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_label, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
