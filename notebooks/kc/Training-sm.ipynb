{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 00:05:55.187280: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from train_model_sm import train\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from yellowbrick.regressor import ResidualsPlot, PredictionError\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (8, 4)\n",
    "rcParams['figure.dpi'] = 100\n",
    "rcParams['font.size'] = 8\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['axes.facecolor'] = '#ffffff'\n",
    "rcParams['lines.linewidth'] = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hyperparameter={\n",
    "\"num_nearest\":60,\n",
    "\"sigma\":2,\n",
    "\"learning_rate\":0.001,\n",
    "\"batch_size\":250,\n",
    "\"num_neuron\":60,\n",
    "\"num_layers\":3,\n",
    "\"size_embedded\":50,\n",
    "\"num_nearest_geo\":45,\n",
    "\"num_nearest_eucli\":45,\n",
    "\"id_dataset\":'kc',\n",
    "\"epochs\":300,\n",
    "\"optimier\":'adam',\n",
    "\"validation_split\":0.1,\n",
    "\"label\":'asi_kc',\n",
    "\"early_stopping\": False,\n",
    "\"graph_label\":'matrix',\n",
    "\"sequence\":'_normalized'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial = train(**hyperparameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node2vec (21608, 19)\n",
      "self.dist_eucli.shape, self.context_struc_eucli_target.shape, self.n2v_eucli.shape (None, 45) (None, 45, 20) (None, 46, 19)\n",
      "self.dist_geo.shape, self.context_geo_target_dist.shape, self.n2v_geo.shape (None, 45) (None, 45, 21) (None, 46, 19)\n",
      "WARNING:tensorflow:From /home/smhan/.conda/envs/TF2/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 00:06:08.797239: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-22 00:06:08.801198: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-22 00:06:08.801458: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-22 00:06:08.802150: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-22 00:06:08.804936: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-22 00:06:08.805191: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-22 00:06:08.805423: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-22 00:06:09.169660: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-22 00:06:09.169926: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-22 00:06:09.170167: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-22 00:06:09.170356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22273 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.input_phenomenon.shape Tensor(\"Placeholder:0\", shape=(None, 19), dtype=float32)\n",
      "self.source_distance.shape (None, 45)\n",
      "self.context.shape (None, 45, 21)\n",
      "self.n2v.shape (None, 46, 19)\n",
      "att_query.shape, att_value.shape (None, 1, 64) (None, 45, 64)\n",
      "att_output (None, 64)\n",
      "feedforward (None, 60)\n",
      "Epoch 1/300\n",
      "self.input_phenomenon.shape Tensor(\"IteratorGetNext:0\", shape=(None, 19), dtype=float32)\n",
      "self.source_distance.shape (None, 45)\n",
      "self.context.shape (None, 45, 21)\n",
      "self.n2v.shape (None, 46, 19)\n",
      "att_query.shape, att_value.shape (None, 1, 64) (None, 45, 64)\n",
      "att_output (None, 64)\n",
      "self.input_phenomenon.shape Tensor(\"IteratorGetNext:0\", shape=(None, 19), dtype=float32)\n",
      "self.source_distance.shape (None, 45)\n",
      "self.context.shape (None, 45, 21)\n",
      "self.n2v.shape (None, 46, 19)\n",
      "att_query.shape, att_value.shape (None, 1, 64) (None, 45, 64)\n",
      "att_output (None, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-22 00:06:12.829902: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-08-22 00:06:12.837332: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x561005a64520 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-22 00:06:12.837359: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-08-22 00:06:12.841916: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-22 00:06:12.934047: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/63 [============================>.] - ETA: 0s - loss: 2.0915 - root_mean_squared_error: 4.1474self.input_phenomenon.shape Tensor(\"IteratorGetNext:0\", shape=(None, 19), dtype=float32)\n",
      "self.source_distance.shape (None, 45)\n",
      "self.context.shape (None, 45, 21)\n",
      "self.n2v.shape (None, 46, 19)\n",
      "att_query.shape, att_value.shape (None, 1, 64) (None, 45, 64)\n",
      "att_output (None, 64)\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.18820, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 6s 14ms/step - loss: 2.0845 - root_mean_squared_error: 4.1398 - val_loss: 0.1882 - val_root_mean_squared_error: 0.2490 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.1382 - root_mean_squared_error: 0.1841\n",
      "Epoch 2: val_loss improved from 0.18820 to 0.13199, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.1352 - root_mean_squared_error: 0.1804 - val_loss: 0.1320 - val_root_mean_squared_error: 0.1665 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0949 - root_mean_squared_error: 0.1238\n",
      "Epoch 3: val_loss improved from 0.13199 to 0.05592, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0943 - root_mean_squared_error: 0.1232 - val_loss: 0.0559 - val_root_mean_squared_error: 0.0779 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0926 - root_mean_squared_error: 0.1157\n",
      "Epoch 4: val_loss improved from 0.05592 to 0.05309, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0926 - root_mean_squared_error: 0.1157 - val_loss: 0.0531 - val_root_mean_squared_error: 0.0748 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0786 - root_mean_squared_error: 0.0974\n",
      "Epoch 5: val_loss did not improve from 0.05309\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0786 - root_mean_squared_error: 0.0974 - val_loss: 0.0752 - val_root_mean_squared_error: 0.0890 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0844 - root_mean_squared_error: 0.0967\n",
      "Epoch 6: val_loss did not improve from 0.05309\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0844 - root_mean_squared_error: 0.0967 - val_loss: 0.0757 - val_root_mean_squared_error: 0.0847 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0439 - root_mean_squared_error: 0.0554\n",
      "Epoch 7: val_loss improved from 0.05309 to 0.04242, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0439 - root_mean_squared_error: 0.0554 - val_loss: 0.0424 - val_root_mean_squared_error: 0.0472 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0399 - root_mean_squared_error: 0.0476\n",
      "Epoch 8: val_loss improved from 0.04242 to 0.03137, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0394 - root_mean_squared_error: 0.0472 - val_loss: 0.0314 - val_root_mean_squared_error: 0.0378 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0446 - root_mean_squared_error: 0.0553\n",
      "Epoch 9: val_loss did not improve from 0.03137\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0457 - root_mean_squared_error: 0.0567 - val_loss: 0.0632 - val_root_mean_squared_error: 0.0680 - lr: 0.0010\n",
      "Epoch 10/300\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0649 - root_mean_squared_error: 0.0731\n",
      "Epoch 10: val_loss did not improve from 0.03137\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0649 - root_mean_squared_error: 0.0731 - val_loss: 0.0378 - val_root_mean_squared_error: 0.0466 - lr: 0.0010\n",
      "Epoch 11/300\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0690 - root_mean_squared_error: 0.0864\n",
      "Epoch 11: val_loss did not improve from 0.03137\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0718 - root_mean_squared_error: 0.0899 - val_loss: 0.1135 - val_root_mean_squared_error: 0.1187 - lr: 0.0010\n",
      "Epoch 12/300\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0705 - root_mean_squared_error: 0.0855\n",
      "Epoch 12: val_loss did not improve from 0.03137\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0701 - root_mean_squared_error: 0.0847 - val_loss: 0.0318 - val_root_mean_squared_error: 0.0389 - lr: 0.0010\n",
      "Epoch 13/300\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0543 - root_mean_squared_error: 0.0612\n",
      "Epoch 13: val_loss did not improve from 0.03137\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0543 - root_mean_squared_error: 0.0611 - val_loss: 0.0660 - val_root_mean_squared_error: 0.0699 - lr: 0.0010\n",
      "Epoch 14/300\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0197 - root_mean_squared_error: 0.0282\n",
      "Epoch 14: val_loss improved from 0.03137 to 0.01181, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0197 - root_mean_squared_error: 0.0282 - val_loss: 0.0118 - val_root_mean_squared_error: 0.0180 - lr: 1.0000e-04\n",
      "Epoch 15/300\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0109 - root_mean_squared_error: 0.0168\n",
      "Epoch 15: val_loss improved from 0.01181 to 0.01075, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0109 - root_mean_squared_error: 0.0168 - val_loss: 0.0107 - val_root_mean_squared_error: 0.0171 - lr: 1.0000e-04\n",
      "Epoch 16/300\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0102 - root_mean_squared_error: 0.0162\n",
      "Epoch 16: val_loss did not improve from 0.01075\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0102 - root_mean_squared_error: 0.0160 - val_loss: 0.0114 - val_root_mean_squared_error: 0.0168 - lr: 1.0000e-04\n",
      "Epoch 17/300\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0098 - root_mean_squared_error: 0.0154\n",
      "Epoch 17: val_loss improved from 0.01075 to 0.00988, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0098 - root_mean_squared_error: 0.0154 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0156 - lr: 1.0000e-04\n",
      "Epoch 18/300\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0092 - root_mean_squared_error: 0.0148\n",
      "Epoch 18: val_loss improved from 0.00988 to 0.00934, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0092 - root_mean_squared_error: 0.0147 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0149 - lr: 1.0000e-04\n",
      "Epoch 19/300\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0089 - root_mean_squared_error: 0.0142\n",
      "Epoch 19: val_loss improved from 0.00934 to 0.00895, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0089 - root_mean_squared_error: 0.0143 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0145 - lr: 1.0000e-04\n",
      "Epoch 20/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0085 - root_mean_squared_error: 0.0139\n",
      "Epoch 20: val_loss improved from 0.00895 to 0.00865, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0085 - root_mean_squared_error: 0.0138 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0139 - lr: 1.0000e-04\n",
      "Epoch 21/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0082 - root_mean_squared_error: 0.0137\n",
      "Epoch 21: val_loss improved from 0.00865 to 0.00824, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0082 - root_mean_squared_error: 0.0135 - val_loss: 0.0082 - val_root_mean_squared_error: 0.0135 - lr: 1.0000e-04\n",
      "Epoch 22/300\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0081 - root_mean_squared_error: 0.0132\n",
      "Epoch 22: val_loss improved from 0.00824 to 0.00785, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0081 - root_mean_squared_error: 0.0132 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0130 - lr: 1.0000e-04\n",
      "Epoch 23/300\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0078 - root_mean_squared_error: 0.0126\n",
      "Epoch 23: val_loss did not improve from 0.00785\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0079 - root_mean_squared_error: 0.0129 - val_loss: 0.0110 - val_root_mean_squared_error: 0.0152 - lr: 1.0000e-04\n",
      "Epoch 24/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0079 - root_mean_squared_error: 0.0128\n",
      "Epoch 24: val_loss improved from 0.00785 to 0.00734, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0078 - root_mean_squared_error: 0.0126 - val_loss: 0.0073 - val_root_mean_squared_error: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 25/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0072 - root_mean_squared_error: 0.0122\n",
      "Epoch 25: val_loss did not improve from 0.00734\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.0072 - root_mean_squared_error: 0.0121 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0121 - lr: 1.0000e-04\n",
      "Epoch 26/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0071 - root_mean_squared_error: 0.0116\n",
      "Epoch 26: val_loss did not improve from 0.00734\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.0070 - root_mean_squared_error: 0.0117 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0135 - lr: 1.0000e-04\n",
      "Epoch 27/300\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0083 - root_mean_squared_error: 0.0125\n",
      "Epoch 27: val_loss improved from 0.00734 to 0.00697, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0082 - root_mean_squared_error: 0.0124 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0114 - lr: 1.0000e-04\n",
      "Epoch 28/300\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0083 - root_mean_squared_error: 0.0125\n",
      "Epoch 28: val_loss did not improve from 0.00697\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0083 - root_mean_squared_error: 0.0125 - val_loss: 0.0116 - val_root_mean_squared_error: 0.0148 - lr: 1.0000e-04\n",
      "Epoch 29/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0086 - root_mean_squared_error: 0.0127\n",
      "Epoch 29: val_loss did not improve from 0.00697\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.0086 - root_mean_squared_error: 0.0126 - val_loss: 0.0106 - val_root_mean_squared_error: 0.0140 - lr: 1.0000e-04\n",
      "Epoch 30/300\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0073 - root_mean_squared_error: 0.0115\n",
      "Epoch 30: val_loss did not improve from 0.00697\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0073 - root_mean_squared_error: 0.0115 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 31/300\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0065 - root_mean_squared_error: 0.0107\n",
      "Epoch 31: val_loss improved from 0.00697 to 0.00616, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0065 - root_mean_squared_error: 0.0106 - val_loss: 0.0062 - val_root_mean_squared_error: 0.0103 - lr: 1.0000e-04\n",
      "Epoch 32/300\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0064 - root_mean_squared_error: 0.0105\n",
      "Epoch 32: val_loss did not improve from 0.00616\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0063 - root_mean_squared_error: 0.0104 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0104 - lr: 1.0000e-04\n",
      "Epoch 33/300\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0059 - root_mean_squared_error: 0.0100\n",
      "Epoch 33: val_loss did not improve from 0.00616\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0059 - root_mean_squared_error: 0.0100 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0100 - lr: 1.0000e-04\n",
      "Epoch 34/300\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0061 - root_mean_squared_error: 0.0101\n",
      "Epoch 34: val_loss improved from 0.00616 to 0.00589, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0061 - root_mean_squared_error: 0.0100 - val_loss: 0.0059 - val_root_mean_squared_error: 0.0095 - lr: 1.0000e-04\n",
      "Epoch 35/300\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0063 - root_mean_squared_error: 0.0098\n",
      "Epoch 35: val_loss did not improve from 0.00589\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0063 - root_mean_squared_error: 0.0099 - val_loss: 0.0064 - val_root_mean_squared_error: 0.0099 - lr: 1.0000e-04\n",
      "Epoch 36/300\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0098 - root_mean_squared_error: 0.0128\n",
      "Epoch 36: val_loss did not improve from 0.00589\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0098 - root_mean_squared_error: 0.0128 - val_loss: 0.0127 - val_root_mean_squared_error: 0.0149 - lr: 1.0000e-04\n",
      "Epoch 37/300\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0077 - root_mean_squared_error: 0.0112\n",
      "Epoch 37: val_loss did not improve from 0.00589\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0077 - root_mean_squared_error: 0.0111 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0099 - lr: 1.0000e-04\n",
      "Epoch 38/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0058 - root_mean_squared_error: 0.0092\n",
      "Epoch 38: val_loss improved from 0.00589 to 0.00547, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0058 - root_mean_squared_error: 0.0092 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0089 - lr: 1.0000e-04\n",
      "Epoch 39/300\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0057 - root_mean_squared_error: 0.0090\n",
      "Epoch 39: val_loss improved from 0.00547 to 0.00518, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0058 - root_mean_squared_error: 0.0090 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0085 - lr: 1.0000e-04\n",
      "Epoch 40/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0058 - root_mean_squared_error: 0.0090\n",
      "Epoch 40: val_loss improved from 0.00518 to 0.00509, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0058 - root_mean_squared_error: 0.0090 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0084 - lr: 1.0000e-04\n",
      "Epoch 41/300\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0058 - root_mean_squared_error: 0.0089\n",
      "Epoch 41: val_loss did not improve from 0.00509\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0058 - root_mean_squared_error: 0.0089 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0088 - lr: 1.0000e-04\n",
      "Epoch 42/300\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0086 - root_mean_squared_error: 0.0112\n",
      "Epoch 42: val_loss did not improve from 0.00509\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0086 - root_mean_squared_error: 0.0112 - val_loss: 0.0086 - val_root_mean_squared_error: 0.0109 - lr: 1.0000e-04\n",
      "Epoch 43/300\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0094 - root_mean_squared_error: 0.0118\n",
      "Epoch 43: val_loss did not improve from 0.00509\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0094 - root_mean_squared_error: 0.0118 - val_loss: 0.0148 - val_root_mean_squared_error: 0.0164 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/300\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0095 - root_mean_squared_error: 0.0118\n",
      "Epoch 44: val_loss did not improve from 0.00509\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0095 - root_mean_squared_error: 0.0117 - val_loss: 0.0063 - val_root_mean_squared_error: 0.0095 - lr: 1.0000e-04\n",
      "Epoch 45/300\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0048 - root_mean_squared_error: 0.0078\n",
      "Epoch 45: val_loss improved from 0.00509 to 0.00478, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0047 - root_mean_squared_error: 0.0078 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0079 - lr: 1.0000e-05\n",
      "Epoch 46/300\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0045 - root_mean_squared_error: 0.0075\n",
      "Epoch 46: val_loss improved from 0.00478 to 0.00473, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0045 - root_mean_squared_error: 0.0075 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0079 - lr: 1.0000e-05\n",
      "Epoch 47/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0045 - root_mean_squared_error: 0.0075\n",
      "Epoch 47: val_loss did not improve from 0.00473\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0045 - root_mean_squared_error: 0.0075 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 48/300\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0044 - root_mean_squared_error: 0.0075\n",
      "Epoch 48: val_loss improved from 0.00473 to 0.00466, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0045 - root_mean_squared_error: 0.0075 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 49/300\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0044 - root_mean_squared_error: 0.0074\n",
      "Epoch 49: val_loss did not improve from 0.00466\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0044 - root_mean_squared_error: 0.0074 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0077 - lr: 1.0000e-05\n",
      "Epoch 50/300\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0044 - root_mean_squared_error: 0.0074\n",
      "Epoch 50: val_loss improved from 0.00466 to 0.00465, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0044 - root_mean_squared_error: 0.0074 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0077 - lr: 1.0000e-05\n",
      "Epoch 51/300\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0044 - root_mean_squared_error: 0.0074\n",
      "Epoch 51: val_loss improved from 0.00465 to 0.00464, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0044 - root_mean_squared_error: 0.0074 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0077 - lr: 1.0000e-05\n",
      "Epoch 52/300\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0044 - root_mean_squared_error: 0.0074\n",
      "Epoch 52: val_loss did not improve from 0.00464\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0044 - root_mean_squared_error: 0.0074 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0078 - lr: 1.0000e-05\n",
      "Epoch 53/300\n",
      "62/63 [============================>.] - ETA: 0s - loss: 0.0044 - root_mean_squared_error: 0.0074\n",
      "Epoch 53: val_loss improved from 0.00464 to 0.00462, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0044 - root_mean_squared_error: 0.0074 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0077 - lr: 1.0000e-05\n",
      "Epoch 54/300\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0044 - root_mean_squared_error: 0.0074\n",
      "Epoch 54: val_loss improved from 0.00462 to 0.00461, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0044 - root_mean_squared_error: 0.0073 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0077 - lr: 1.0000e-06\n",
      "Epoch 55/300\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0043 - root_mean_squared_error: 0.0074\n",
      "Epoch 55: val_loss did not improve from 0.00461\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0043 - root_mean_squared_error: 0.0073 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0077 - lr: 1.0000e-06\n",
      "Epoch 56/300\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0043 - root_mean_squared_error: 0.0073\n",
      "Epoch 56: val_loss improved from 0.00461 to 0.00461, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0043 - root_mean_squared_error: 0.0073 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0077 - lr: 1.0000e-06\n",
      "Epoch 57/300\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0043 - root_mean_squared_error: 0.0073\n",
      "Epoch 57: val_loss did not improve from 0.00461\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0043 - root_mean_squared_error: 0.0073 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0077 - lr: 1.0000e-06\n",
      "Epoch 58/300\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0043 - root_mean_squared_error: 0.0073\n",
      "Epoch 58: val_loss improved from 0.00461 to 0.00460, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0043 - root_mean_squared_error: 0.0073 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0077 - lr: 1.0000e-06\n",
      "Epoch 59/300\n",
      "57/63 [==========================>...] - ETA: 0s - loss: 0.0043 - root_mean_squared_error: 0.0072\n",
      "Epoch 59: val_loss improved from 0.00460 to 0.00459, saving model to /disk1/jupyter/smhan/ASI-revised/output_sm/models/kc/asi_kc_weights.hdf5\n",
      "63/63 [==============================] - 1s 10ms/step - loss: 0.0043 - root_mean_squared_error: 0.0073 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0077 - lr: 1.0000e-07\n",
      "Epoch 60/300\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0043 - root_mean_squared_error: 0.0073\n",
      "Epoch 60: val_loss did not improve from 0.00459\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0043 - root_mean_squared_error: 0.0073 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0077 - lr: 1.0000e-07\n",
      "Epoch 61/300\n",
      "59/63 [===========================>..] - ETA: 0s - loss: 0.0043 - root_mean_squared_error: 0.0073\n",
      "Epoch 61: val_loss did not improve from 0.00459\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0043 - root_mean_squared_error: 0.0073 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0077 - lr: 1.0000e-07\n",
      "Epoch 62/300\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0044 - root_mean_squared_error: 0.0074\n",
      "Epoch 62: val_loss did not improve from 0.00459\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0043 - root_mean_squared_error: 0.0073 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0077 - lr: 1.0000e-07\n",
      "Epoch 63/300\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0043 - root_mean_squared_error: 0.0074\n",
      "Epoch 63: val_loss did not improve from 0.00459\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0043 - root_mean_squared_error: 0.0073 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0077 - lr: 1.0000e-07\n",
      "Epoch 64/300\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0044 - root_mean_squared_error: 0.0074\n",
      "Epoch 64: val_loss did not improve from 0.00459\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0043 - root_mean_squared_error: 0.0073 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0077 - lr: 1.0000e-08\n",
      "Epoch 65/300\n",
      "58/63 [==========================>...] - ETA: 0s - loss: 0.0044 - root_mean_squared_error: 0.0074\n",
      "Epoch 65: val_loss did not improve from 0.00459\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0043 - root_mean_squared_error: 0.0073 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0077 - lr: 1.0000e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/300\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0043 - root_mean_squared_error: 0.0073\n",
      "Epoch 66: val_loss did not improve from 0.00459\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0043 - root_mean_squared_error: 0.0073 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0077 - lr: 1.0000e-08\n",
      "Epoch 67/300\n",
      "60/63 [===========================>..] - ETA: 0s - loss: 0.0043 - root_mean_squared_error: 0.0074\n",
      "Epoch 67: val_loss did not improve from 0.00459\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0043 - root_mean_squared_error: 0.0073 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0077 - lr: 1.0000e-08\n",
      "Epoch 68/300\n",
      "61/63 [============================>.] - ETA: 0s - loss: 0.0043 - root_mean_squared_error: 0.0073\n",
      "Epoch 68: val_loss did not improve from 0.00459\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0043 - root_mean_squared_error: 0.0073 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0077 - lr: 1.0000e-08\n",
      "Epoch 69/300\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0043 - root_mean_squared_error: 0.0073\n",
      "Epoch 69: val_loss did not improve from 0.00459\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.0043 - root_mean_squared_error: 0.0073 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0077 - lr: 1.0000e-09\n",
      "self.input_phenomenon.shape Tensor(\"IteratorGetNext:0\", shape=(None, 19), dtype=float32)\n",
      "self.source_distance.shape (None, 45)\n",
      "self.context.shape (None, 45, 21)\n",
      "self.n2v.shape (None, 46, 19)\n",
      "att_query.shape, att_value.shape (None, 1, 64) (None, 45, 64)\n",
      "att_output (None, 64)\n",
      "136/136 [==============================] - 1s 3ms/step\n",
      "541/541 [==============================] - 1s 3ms/step\n",
      "self.input_phenomenon.shape Tensor(\"IteratorGetNext:0\", shape=(None, 19), dtype=float32)\n",
      "self.source_distance.shape (None, 45)\n",
      "self.context.shape (None, 45, 21)\n",
      "self.n2v.shape (None, 46, 19)\n",
      "att_query.shape, att_value.shape (None, 1, 64) (None, 45, 64)\n",
      "att_output (None, 64)\n",
      "70/70 [==============================] - 1s 3ms/step\n",
      "self.input_phenomenon.shape Tensor(\"IteratorGetNext:0\", shape=(None, 19), dtype=float32)\n",
      "self.source_distance.shape (None, 45)\n",
      "self.context.shape (None, 45, 21)\n",
      "self.n2v.shape (None, 46, 19)\n",
      "att_query.shape, att_value.shape (None, 1, 64) (None, 45, 64)\n",
      "att_output (None, 64)\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "self.input_phenomenon.shape Tensor(\"IteratorGetNext:0\", shape=(None, 19), dtype=float32)\n",
      "self.source_distance.shape (None, 45)\n",
      "self.context.shape (None, 45, 21)\n",
      "self.n2v.shape (None, 46, 19)\n",
      "att_query.shape, att_value.shape (None, 1, 64) (None, 45, 64)\n",
      "att_output (None, 64)\n",
      "70/70 [==============================] - 0s 3ms/step\n",
      "self.input_phenomenon.shape Tensor(\"IteratorGetNext:0\", shape=(None, 19), dtype=float32)\n",
      "self.source_distance.shape (None, 45)\n",
      "self.context.shape (None, 45, 21)\n",
      "self.n2v.shape (None, 46, 19)\n",
      "att_query.shape, att_value.shape (None, 1, 64) (None, 45, 64)\n",
      "att_output (None, 64)\n",
      "18/18 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "dataset,\\\n",
    "result,\\\n",
    "fit,\\\n",
    "embedded_train,\\\n",
    "embedded_test,\\\n",
    "predict_regression_train,\\\n",
    "predict_regression_test = spatial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################# Test ##########################\n",
      "MALE test:.... 0.010155750990524329\n",
      "RMSE test:.... 9393.282069008725\n",
      "MAPE test:.... 0.9266565033006373\n",
      "################# Train ##########################\n",
      "MALE train:.... 0.004363472719885306\n",
      "RMSE train:.... 8225.381960082024\n",
      "MAPE train:.... 0.28766725051267705\n"
     ]
    }
   ],
   "source": [
    "print('################# Test ##########################')\n",
    "print('MALE test:.... {}'.format(result[0]))\n",
    "print('RMSE test:.... {}'.format(result[1]))\n",
    "print('MAPE test:.... {}'.format(result[2]))\n",
    "print('################# Train ##########################')\n",
    "print('MALE train:.... {}'.format(result[3]))\n",
    "print('RMSE train:.... {}'.format(result[4]))\n",
    "print('MAPE train:.... {}'.format(result[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "# metric\n",
    "def metric(pred, label):\n",
    "    assert label.shape == pred.shape\n",
    "    \n",
    "    with np.errstate(divide = 'ignore', invalid = 'ignore'):\n",
    "        mask = np.not_equal(label, 0)\n",
    "        mask = mask.astype(np.float32)\n",
    "        mask /= np.mean(mask)\n",
    "        male = np.abs(np.subtract(np.log(pred), np.log(label))).astype(np.float32)\n",
    "        male = np.nan_to_num(male * mask)\n",
    "        male = np.mean(male)\n",
    "        mae = np.abs(np.subtract(pred, label)).astype(np.float32)\n",
    "        rmse = np.square(mae)\n",
    "        mape = np.divide(mae, label)\n",
    "        mae = np.nan_to_num(mae * mask)\n",
    "        mae = np.mean(mae)\n",
    "        rmse = np.nan_to_num(rmse * mask)\n",
    "        rmse = np.sqrt(np.mean(rmse))\n",
    "        mape = np.nan_to_num(mape * mask)\n",
    "        mape = np.median(mape) # np.mean(mape) -- author leverages median\n",
    "    return male, rmse, mape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.010155751, 9393.282, 0.009266565033006758)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label = np.exp(dataset.y_test)\n",
    "y_pred = np.exp(result[6].flatten())\n",
    "metric(y_pred, y_label) # should be same value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f99a05258a0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_label, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
